---
title: "Comparing E-G predictions with CRISPR data"
date: "`r format(Sys.time(), '%B %d, %Y')`"
params:
  rmd: "comparePredictionsToExperiment.Rmd"
output:
  html_document:
    number_sections: yes
    toc: yes
---

```{r setupDocument, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


```{r attachPackages, message=FALSE, warning=FALSE}
# attach required packages and functions
library(tidyverse)
library(here)
library(DT)
library(plotly)
library(ROCR)
library(caTools)
library(UpSetR)
source(file.path(snakemake@scriptdir, "crisprComparisonPlotFunctions.R"))
```

```{r loadData}
# load merged data and pred_config file
merged <- fread(here(snakemake@input$merged), colClasses = c("ValidConnection" = "character"))
pred_config <- fread(here(snakemake@input$pred_config),
                     colClasses = c("alpha" = "numeric", "color" = "character"))

# extract predictions and experiment input files from config in snakemake object
comp_config <- snakemake@config$comparisons[[snakemake@wildcards$comparison]]
expt_file <- basename(comp_config$expt)
pred_file <- basename(unlist(comp_config$pred))
```

<br>

This is the output for the comparison **`r snakemake@wildcards$comparison`**. Following analyses
evaluate how well the experimental data agrees with the predictions of CRE - gene pairs. Following
input files were used:

Experimental data: **`r expt_file`**  
Predictions: **`r pred_file`**

Following parameters in the config file **`r snakemake@input$pred_config`** were used to overlap
predictions with experimental data and to assess performance of predictors. If no config file was
provided, this was generated using default values. It's strongly recommended to use a prediction
config file to control how predictors should be treated.
```{r}
options(htmlwidgets.TOJSON_ARGS = list(na = 'string'))
datatable(pred_config, options = list(pageLength = 20), autoHideNavigation = TRUE)
```

***

# Precision-Recall performance
Precision-recall (PR) curves are used for comparing the performance of different predictors on the
experimental data. The area under the PR curve (AUPRC) provides a single metric of a predictors
performance.

```{r processInput}
# add baseline predictors to pred_config
pred_config <- data.frame(
    pred_id = "baseline",
    pred_col = c("distToTSS", "nearestTSS", "nearestGene"),
    boolean = c(FALSE, TRUE, TRUE),
    alpha = c(1e4, 1, 1),
    aggregate_function = c("mean", "max", "max"),
    fill_value = c(Inf, 0, 0),
    inverse_predictor = c(TRUE, FALSE, FALSE),
    pred_name_long = c("Distance to TSS", "Nearest TSS", "Nearest Gene"),
    color = rep(NA_character_, 3)
  ) %>% 
  rbind(pred_config, .)

# set colors for baseline predictors if colors are set for the other predictors
if (any(!is.na(pred_config$color))) {
  pred_config[tail(seq_len(nrow(pred_config)), 3), "color"] <- c("#ffa600", "#595959", "#bebebe")
  pred_colors <- deframe(select(pred_config, pred_name_long, color))
} else {
  pred_colors <- NULL
}

# add unique predictor identifier to pred_config
pred_config <- pred_config %>% 
  unite(pred_id, pred_col, col = pred_uid, sep = ".", remove = FALSE)

# add the unique predictor identifiers and long names to merged data
merged <- pred_config %>% 
  select(pred_id, pred_col, pred_uid, pred_name_long) %>% 
  left_join(x = merged, y = ., by = c("pred_id", "pred_col"))

# filter for valid connections
merged <- subset(merged, ValidConnection == "TRUE")

# filter out CRE-G pairs with missing data if specified
if (snakemake@params$include_missing_predictions == FALSE) {
  merged <- merged[merged$Prediction == 1, ]
}

# get default alpha value for predictors that do not have alpha specified (default = min alpha)
pred_config <- getDefaultAlpha(pred_config, merged = merged)
```

```{r computePRC}
# get all cell types in merged
cell_types <- unique(merged$ExperimentCellType)
if (length(cell_types) > 1) {
  cell_types <- c("combined", cell_types)
}
names(cell_types) <- cell_types

# compute precision-recall tables for all cell types
pos_col <- "Regulated"
pr <- lapply(cell_types, FUN = calcPRCurves, df = merged, pred_config = pred_config,
             pos_col = pos_col)

# combine pr tables into one table and save to file for other downstream analyses
pr_table <- rbindlist(pr, idcol = "ExperimentCellType")
write_tsv(pr_table, file = here(file.path(dirname(snakemake@output[[1]]), "pr_table.txt.gz")))

# create performance summary tables
perf_summary <- lapply(pr, FUN = makePRSummaryTable, pred_config = pred_config,
                       min_sensitivity = snakemake@params$min_sensitivity)
```

```{r plotPRC, warning=FALSE}
# calculate percentage of experimental true positives in the experimental dataset per cell type
pct_pos <- lapply(cell_types, FUN = calcPctPos, df = merged, pos_col = pos_col)

# make PRC plots
pct_pos <- pct_pos[names(pr)]
pr_plots <- mapply(FUN = makePRCurvePlot, pr_df = pr, pct_pos = pct_pos,
                   MoreArgs = list(pred_config = pred_config,
                                   min_sensitivity = snakemake@params$min_sensitivity,
                                   plot_name = "PRC full experimental data",
                                   line_width = 1.2, point_size = 3.5, text_size = 13,
                                   colors = pred_colors),
                   SIMPLIFY = FALSE)

# save plots to file
plotdir <- here(dirname(snakemake@output[[1]]), "plots")
dir.create(plotdir, recursive = TRUE, showWarnings = FALSE)
pr_plot_files <-  here(plotdir, paste0(names(pr_plots), "_prc_full_expt_data.pdf"))
for (i in seq_along(pr_plots)) {
  ggsave(pr_plots[[i]], filename = pr_plot_files[[i]], height = 4.5, width = 7.5, device = "pdf")
}
```

## Precision-recall curves {.tabset .tabset-pills}

```{r results='asis', fig.cap=cap, fig.height=4.5, fig.width=7.5, warning=FALSE}
# print plots for every cell type in tabs
for (i in cell_types){
  cat("###", i, '{.unlisted .unnumbered}', '\n', '<br>', '\n')
  plot(pr_plots[[i]])
  cat('\n', '<br>', '\n\n')
}
cat("## {.unlisted .unnumbered}")

# figure caption
cap <- paste("Precision-recall curves for all predictors in all matching experimental cell types.",
             "Dots represent alpha cutoff values as specified in pred_config file. If no alpha was",
             "set, the minium alpha in predictions was taken by default, respectively the maximum",
             "for inverse predictors. Distance to TSS was added as baseline predictor and computed",
             "from the provided 'gene universe'.")
```

## Performance summary

```{r perfSummary, fig.cap = cap}
# convert pr summary tables to one table and reformat for printing
perf_summary_print <- perf_summary %>% 
  bind_rows(.id = "cell_type") %>% 
  select(cell_type, predictor = pred_name_long, AUPRC, max_F1, alpha_cutoff, sensitivity_at_cutoff,
         precision_at_cutoff, min_sensitivity, sensitivity_at_min_sensitivity,
         precision_at_min_sensitivity)

# pretty print PR summary table
datatable(
  perf_summary_print,
  extensions = c("FixedColumns", "Buttons"),
  options = list(
    pageLength = 20,
    dom = 'Bfrtip',
    scrollX = TRUE,
    fixedColumns = list(leftColumns = 3),
    buttons = c('copy', 'csv', 'excel', 'pdf', 'print')
  ),
  autoHideNavigation = TRUE
)

cap <- paste("Precision-recall performance summary for predictors. Table shows preformance metrics",
             "and precision and recall at specified alpha and minimum sensitity (recall) of 0.7.")
```

***

# Predictor scores versus experimental outcome {.tabset .tabset-pills}
The scores of each predictor is compared between experimental positives and negatives to get another
assessment of how well it distinguishes true enhancer - gene pairs from negatives.

```{r, warning=FALSE}
# remove boolean predictors for these plots
bool_preds <- pull(filter(pred_config, boolean == TRUE), pred_uid)
merged_quant <- filter(merged, !pred_uid %in% bool_preds)

# create plots showing predictor values as a function of experimental outcome
pred_plots <- lapply(cell_types, FUN = plotPredictorsVsExperiment, df = merged_quant,
                     pos_col = pos_col, pred_names_col = "pred_name_long", point_size = 2,
                     text_size = 13)

# calculate plot dimensions based on number of predictors
pred_plots_dims <- get_row_col(pred_plots[[1]])
plot_height <- ceiling(pred_plots_dims[1] * 2.5)
plot_width  <- ceiling(pred_plots_dims[2] * 3.5)

# save scatter plots to files
for (n in names(pred_plots)) {
  ggsave(pred_plots[[n]], filename = here(plotdir, paste0(n, "_predictor_vs_experiment.pdf")),
         height = plot_height, width = plot_width, device = "pdf")
}
```

```{r, results='asis', fig.cap=cap, fig.height=plot_height, fig.width=plot_width, warning = FALSE}
# print plots for every cell type in tabs
for (i in cell_types){
  cat("##", i, '{.unlisted .unnumbered}', '\n', '<br>', '\n')
  plot(pred_plots[[i]])
  cat('\n', '<br>', '\n\n')
}
cat("# {.unlisted .unnumbered}")

cap <- paste("Predictor scores vs. experimental outcome for all predictor. Each point represents",
  "one E-G pair in the experimental data. Cases where the predictor value is 0 or infinite might",
  "correspond to E-G pairs that were not found in predictions and predicor values were filled in",
  "according to the prediction config file")
```

***

# Effect size vs predictors {.tabset .tabset-pills}
Each predictor listed in the prediction data is plotted against the effect size of enhancer
perturbations reported in the experimental data (e.g. percent change in expression). These plots
show how well a predictor is associated with effects observed in CRISPRi enhancer screens in an
intuitive way.

```{r effectSizeScatter, include=FALSE}
# add label for each pair based on whether it's significant and activates or represses it's target
merged_quant <- labelPairs(merged_quant, sig_col = "Significant")

# make scatter plots
es_scatters <- lapply(cell_types, FUN = predScatterPlots, df = merged_quant, y_col = "EffectSize",
                      point_size = 2, text_size = 13, alpha_value = 1,
                      pred_names_col = "pred_name_long")

# calculate plot dimensions based on number of predictors
es_scatter_dims <- get_row_col(es_scatters[[1]])
plot_height <- ceiling(es_scatter_dims[1] * 3.5)
plot_width  <- ceiling(es_scatter_dims[2] * 3.5)

# save scatter plots to files
for (n in names(es_scatters)) {
  ggsave(es_scatters[[n]], filename = here(plotdir, paste0(n, "_EffectSize_scatter_plots.pdf")),
         height = plot_height, width = plot_width, device = "pdf")
}
```

```{r, results='asis', fig.cap=cap, fig.height=plot_height, fig.width=plot_width}
# print plots for every cell type in tabs
for (i in cell_types){
  cat("##", i, '{.unlisted .unnumbered}', '\n', '<br>', '\n')
  plot(es_scatters[[i]])
  cat('\n', '<br>', '\n\n')
}
cat("# {.unlisted .unnumbered}")

cap <- paste("Predictors versus experimental effect size. Effect size is taken from 'EffectSize'",
             "column in experimental data, while predictors correspond to predictor values from", 
             "prediction files.")
```

***

# Properties of the experimental dataset
Different features of the experimental data are investigated.

## Distance to TSS distribution {.tabset .tabset-pills}
```{r distToTSSDistr}
# create distance to TSS distributions for all cell types
dist_distr <- lapply(cell_types, FUN = plotDistanceDistribution, df = merged,
                     dist = "baseline.distToTSS", pos_col = "Regulated", text_size = 13)

# save plots to pdfs
for (n in names(dist_distr)) {
  ggsave(dist_distr[[n]], filename = here(plotdir, paste0(n, "_distToTSS_distribution.pdf")),
         height = 5, width = 7, device = "pdf")
}
```

```{r, results='asis', fig.cap=cap, fig.height=5, fig.width=7}
# print plots for every cell type in tabs
for (i in cell_types){
  cat("###", i, '{.unlisted .unnumbered}', '\n', '<br>', '\n')
  plot(dist_distr[[i]])
  cat('\n', '<br>', '\n\n')
}
cat("## {.unlisted .unnumbered}")

cap <- paste("Distance to TSS distributions for all E-G pairs in experimental data. E-G pairs are",
  "partitioned according to whether they were identified as true enhancer gene interactions or
  negatives")
```

## Overlapping features
A plot showing the number of experimentally tested candidate enhancers overlapping provided genomic features. If no features were provided, this plot is not generated.

```{r genomicFeatures}
# genomic features that were overlapped with enhancers in merged data
features<- names(comp_config$annotation_features)

if (length(features > 0)) {
  
  # columns in merged data containing information on overlapping features
  feature_cols <- paste0("overlaps_", features)
  
  # make upset plots from features overlapping experimentally tested enhancers for each cell type
  overlap_plots <- lapply(cell_types, FUN = plotOverlappingFeatures, df = merged,
                          feature_cols = feature_cols)
  
  # save plots
  for (n in names(overlap_plots)) {
    pdf(here(plotdir,  paste0(n, "_overlappingFeatures.pdf")), height = 5, width = 7, onefile = FALSE)
    print(overlap_plots[[n]])
    dev.off()
  }
}
```

```{r, results='asis', fig.height=5, fig.width=7, fig.cap=cap}
if (length(features > 0)) {
  
  # print plots for every cell type in tabs
  for (i in cell_types){
    cat("###", i, '{.unlisted .unnumbered}', '\n', '<br>', '\n')
    print(overlap_plots[[i]])
    cat('\n', '<br>', '\n\n')
  }
  cat("## {.unlisted .unnumbered}")
  
  cap <- paste("Genomic features overlapping experimentally tested enhancers.")
  
}
```


***

# Sources
* <a download="comparePredictionsToExperiment.Rmd" href="`r base64enc::dataURI(file = params$rmd, mime = 'text/rmd',
    encoding = 'base64')`">R Markdown source file (to produce this document)</a>
